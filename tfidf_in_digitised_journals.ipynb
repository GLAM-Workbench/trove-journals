{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF in digitised journals\n",
    "\n",
    "This notebook calculates TF-IDF values for words in digitised journals harvested from Trove. See also the notebook on [word frequences in digitised journals](word_frequences_in_digitised_journals.ipynb). More documentation coming..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tarfile\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import altair as alt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a journal\n",
    "\n",
    "Create a dropdown widget to select a digitised journal. The cells below will use this widget to get the value of the currently selected journal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load details of digitised journals from CSV\n",
    "df_journals = pd.read_csv('digital-journals-with-text.csv').sort_values(by='title')\n",
    "journal_list = [(f\"{j['title']} ({j['issues_with_text']} issues)\", j['directory']) for j in df_journals[['title', 'directory', 'issues_with_text']].to_dict('records')]\n",
    "journals = widgets.Dropdown(options=journal_list, disabled=False)\n",
    "display(journals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all the issues of the journal\n",
    "\n",
    "Download a zip file containing the OCRd text of all the selected journal's available issues from the repository on CloudStor. Then unzip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs_path(journal):\n",
    "    path = os.path.join('downloads', journal, 'texts')\n",
    "    docs_path = [p for p in sorted(Path(path).glob('*.txt'))]\n",
    "    return docs_path\n",
    "\n",
    "def download_journal(journal):\n",
    "    '''\n",
    "    Download the OCRd text of the selected journal from the respoitory on CloudStor. \n",
    "    '''\n",
    "    \n",
    "    # Create a directory to put the downloaded files\n",
    "    path = os.path.join('downloads', journal)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    # To get a sub-folder on Cloudstor you add a 'path' parameter\n",
    "    params = {\n",
    "        'path': f'/{journal}/texts'\n",
    "    }\n",
    "    \n",
    "    # Get the zipped texts folder from Cloudstor -- note the 'download' in the url to get the zipped folder\n",
    "    response = requests.get('https://cloudstor.aarnet.edu.au/plus/s/QOmnqpGQCNCSC2h/download', params=params)\n",
    "    \n",
    "    # Unzip the zip!\n",
    "    zipped = zipfile.ZipFile(BytesIO(response.content))\n",
    "    zipped.extractall(path)\n",
    "    \n",
    "    print(f'{len(get_docs_path(journal))} issues downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OCRd text of the selected journal\n",
    "download_journal(journals.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(journal):\n",
    "    docs_path = get_docs_path(journal)\n",
    "    for p in docs_path:\n",
    "        yield p.read_text(encoding='utf-8').strip()\n",
    "\n",
    "def get_file_names(journal):\n",
    "    return [p.stem for p in get_docs_path(journal)]\n",
    "\n",
    "def get_years(journal):\n",
    "    '''\n",
    "    Get a list of years extracted from the filenames of the issues.\n",
    "    '''\n",
    "    years = []\n",
    "    for doc in get_docs_path(journal):\n",
    "        try:\n",
    "            matches = re.findall(r'-((?:18|19|20)\\d{2})-', doc.stem)\n",
    "            years.append(int(matches[-1]))\n",
    "        except IndexError:\n",
    "            print(f'YEAR NOT FOUND: {doc}')\n",
    "    return sorted(list(set(years)))\n",
    "\n",
    "def get_docs_year(journal):\n",
    "    '''\n",
    "    Combine all the issues from a year into a single document ready to be fed into the pipeline.\n",
    "    '''\n",
    "    docs_year = {}\n",
    "    path = Path(f'{journals}/texts')\n",
    "    for doc in get_docs_path(journal):\n",
    "        try:\n",
    "            matches = re.findall(r'-((?:18|19|20)\\d{2})-', doc.stem)\n",
    "            year = int(matches[-1])\n",
    "        except IndexError:\n",
    "            print(f'YEAR NOT FOUND: {doc}')\n",
    "        else:\n",
    "            try:\n",
    "                docs_year[year].append(doc)\n",
    "            except KeyError:\n",
    "                docs_year[year] = [doc]\n",
    "    for y in sorted(docs_year.keys()):\n",
    "        year_doc = ' '.join([p.read_text(encoding='utf-8').strip() for p in docs_year[y]])\n",
    "        yield year_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the TF-IDF values for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=10000, ngram_range=(1,1), min_df=5, max_df=0.5)\n",
    "# preprocessor = lambda x: re.sub(r'(\\d[\\d\\.])+', 'NUM', x.lower())\n",
    "X_freq = np.asarray(vectorizer.fit_transform(get_docs_year(journals.value)).todense())\n",
    "df_tfidf_years = pd.DataFrame(X_freq, columns=vectorizer.get_feature_names(), index=get_years(journals.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a CSV\n",
    "#df_freq.to_csv(f'{journals.value}-word-frequencies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "df_tfidf_years.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the words each year with the highest TF-IDF scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top words per year\n",
    "df_years_top = pd.DataFrame({n: df_tfidf_years.T[col].nlargest(10).index.tolist() for n, col in enumerate(df_tfidf_years.T)}).T\n",
    "df_years_top.index = get_years(journals.value)\n",
    "df_years_top.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And know we'll display the results in one huuuge chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_chart = alt.vconcat()\n",
    "years = get_years(journals.value)\n",
    "# Number of columns\n",
    "cols = 4\n",
    "start = 0\n",
    "while start < len(years):\n",
    "    row = alt.hconcat()\n",
    "    for year in years[start:start+cols]:\n",
    "        df_year_word_count = pd.DataFrame([{'word': w, 'count': df_tfidf_years.loc[year][w]} for w in df_years_top.loc[year].tolist()])\n",
    "        chart = alt.Chart(df_year_word_count).mark_bar().encode(\n",
    "            y='word:N',\n",
    "            x='count:Q',\n",
    "        ).properties(width=120, height=120, title=str(year), columns=4)\n",
    "        row |= chart\n",
    "    compound_chart &= row\n",
    "    start += cols\n",
    "compound_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
